### Introduction

 build a new multi-tenant serverelss language runtime focused on low overheads and resourcereuse, using lightweight isolation built into the runtime itself.



### 背景

无服务器计算提高了抽象级别，使用户与执行环境完全分离。这样做，它使分布式系统更易于访问、更灵活并且可能更便宜。小型、可并行化功能的相关编程模型与微服务架构完美契合，在大数据处理中具有潜在应用 [1]。该技术在移动后端、物联网和下游数据处理方面具有更广泛的用例。

尽管无服务器具有明显的潜力，但它尚未获得显着的吸引力，并且仍然存在一些未解决的问题。一个几乎无处不在的设计决策是在其自己的 Docker 容器中运行每个单独的无服务器函数，就像在 OpenLambda [2]、OpenWhisk [3] 和 OpenFaaS [4] 中的情况。这很容易推理并提供良好的隔离保证。平台还可以利用现有的容器编排框架，如 Kubernetes [5]，并免费获得负载平衡、网络和容器管理功能。最后，容器为许多用户所熟悉，成熟的工具使它们易于使用。

容器的一个不幸的缺点是它们的启动开销，这导致了无服务器平台中的“冷启动”问题。当容器无法为请求提供服务时会发生冷启动，并且启动干净的执行环境会导致延迟和资源消耗激增。容器启动时间可以达到数百毫秒 [6] 的数量级，比延迟关键系统中许多请求的持续时间高一个数量级。这种对响应时间的不可预测的影响使得实现低延迟的无服务器应用程序变得不可行。这个问题在 [2] 和 [7] 中有更详细的介绍，特别是当用户看到高比例的冷启动时吞吐量非常低。

冷启动可以通过预先配置资源来缓解，这是 OpenFaaS [4] 中采用的一种方法。 OpenFaaS 为每个部署的功能保持一个容器运行，从而解决了部分问题，但增加了空闲用户的开销。这种方法不会减轻系统水平扩展时遇到的其他形式的冷启动。

**通过将函数隔离在各自的容器中，我们失去了共享和重用资源的大部分能力**。随着更多功能的部署，这会导致管理费用快速增长。为单个函数每秒处理 30 个请求可能需要单个容器，相反，每一个每秒接收一个请求的 30 个函数需要 30 个单独的容器，但可能正在执行等量的工作。当函数具有共同的运行时或类似的依赖关系时，这种硬隔离似乎很浪费，并且可以从支持共享和重用的替代方法中获得很多。

无服务器计算中另一个有趣的问题是共享状态。大多数无服务器平台**仅支持无状态功能**，需要用户提供和管理外部存储以在请求之间共享数据。这排除了大多数数据密集型应用程序，因为在每次函数调用时对该外部存储的 I/O 都非常耗时。在 OpenLambda 上运行数据密集型应用程序是在 PyWren [1] 中处理的，它使用系统调整和外部存储的组合来实现良好的性能和弹性扩展。不幸的是，这对于普通用户来说仍然是不可行的，而且距离成熟的大数据环境还有很长的路要走。已经初步尝试构建有状态的无服务器框架，例如 AWS Step Functions [8] 和 Apache Openwhisk Composer [9]，但这些仍处于起步阶段。 

### 调查

1. Openwhisk  

   Apache OpenWhisk [3] 是一个著名的开源无服务器平台，使用 Akka 框架 [10] 构建。用户可以提交以多种支持的语言编写的函数，以便按需或根据触发器运行。如果默认情况下不支持他们想要的语言，他们可以指定自己的 customDocker 镜像来执行他们的代码。函数没有预先分配资源，因此在收到第一个请求时会创建一个具有所需依赖项的容器。容器在处理请求后会暂停，并在特定超时后被清除。如果在此超时时间内发出重复请求，则容器将取消暂停并重用。如果请求更频繁，则会创建多个容器来运行相同的功能。当系统过载时，暂停的容器将被销毁，为新的容器腾出空间。这种方法类似于 [7] 中详细讨论的 OpenLambda 方法。调度由一个或多个“控制器”节点集中和处理，这些节点将请求转发到执行请求的“调用者”节点。控制器将始终尝试将每个函数的请求路由到同一个调用程序节点，以最大化“热启动”的概率。如果所需的调用程序过载，控制器将选择另一个调用程序，该调用程序将开始创建更多容器来运行该函数 



尽管 Openwhisk 是一个流行的备受瞩目的框架，但似乎很少有现有的工作关注其性能。以下实验在具有两台调用程序机器和一台控制器机器的 OpenWhisk 集群上运行。每个调用者都有一个 Intel Xeon E3-1220 3.1Ghz 处理器和 16GB DRAM。所有函数都是用 Java 编写的相同的无操作（请注意，语言选择与结果几乎没有什么不同）。调用者的池中最多允许有 64 个容器，从而使系统有可能同时运行多达 128 个容器。**在非常低的负载下，我们观察到高延迟，因为容器在每次请求时都会被实例化、使用和清除**。这与 [2] 中讨论的 OpenLambda 效果相同。图 1 显示了 OpenWhisk 在中高负载下的行为。所有图表都显示了分布在不同数量函数上的等效吞吐量的系统指标，即对于 10 个函数，每个函数处理十分之一的吞吐量，而对于一个函数，单个函数处理所有负载。在图 1a 中，我们看到延迟如何随吞吐量增加。随着系统开始对请求进行排队，较少数量的功能会急剧增加。当负载分布在更多功能上时，这种增加不会那么陡峭，因为系统能够将工作分布在更多容器中。此吞吐量级别的所有请求都将由热启动提供服务，因此延迟为数十毫秒。在图 1b 和图 1c 中，我们看到资源需求随着吞吐量的增加而发生变化。图 1b 显示了调用程序机器用于维持给定吞吐量一分钟的 CPU 周期总数。如图所示，随着我们使用更多函数，这个数字显着增加。图 1c 显示了调用程序机器上的平均内存需求，并讲述了一个类似的故事。不同数量的函数的内存需求差异很大，在每个容器中运行单独的 JVM 会加剧这种差异。在某个吞吐量调用程序机器开始达到其容器限制并且无法进一步扩展。发生这种情况时，Openwhisk 会驱逐温暖的容器，因此强制冷启动率高于正常情况。这种行为会导致螺旋式下降并导致颠簸，如图 2 所示。在这里，我们看到了提交的请求率与实现的实际吞吐量。在某些时候，系统无法再处理传入的请求并且响应率崩溃。这取决于调度方法和容器强加的隔离。 



### 研究问题

1. Runtime  

如上所述，基于容器的运行时有一些缺点。 低延迟应用程序的启动时间是不可接受的，并且完全隔离排除了资源重用。 我将研究语言运行时本身的隔离性，重点关注以低开销和最短启动时间并行运行不受信任的函数。 隔离机制可能基于操作系统抽象，这是现有文献中的一个共同主题 [11-13]。 为了减少启动时间，支持特定语言的依赖管理和重用至关重要。 该主题在 [7] 中的无服务器 Python 上下文中进行了讨论。 使用 unikernel 和快速启动的 VM 来建立轻量级环境 [6, 14] 很有趣，我将对此进行研究。 通过构建这样一个运行时，我的目标是减少冷启动的幅度并允许提供者更好地管理资源 

2. Scheduling  

   当前的开源无服务器平台具有相当简单的调度逻辑，缺乏 SLO 并提供最小的公平保证。 大多数人都在调度短期容器，对托管没有好处，因此它们的智能程度有限。 通过引入允许资源共享的运行时，可以在调度时利用托管和依赖管理。 通过考虑这些因素并引入更严格的公平性，我计划减少用户看到的延迟，同时提高提供商的资源效率。 现有的关于调度云工作负载、SLO 和公平性的文献将在这里 [15, 16] 与低延迟调度 [17, 18] 相关。 

3. Shared State  

​	无服务器平台缺乏对状态的原生支持给用户带来了负担，同时排除了许多用例，尤其是那些处理大量数据的用例。 通过将状态管理引入平台，我将能够研究可变分布式状态、缓存、托管及其相关的编程抽象。 为了实现该领域的任何目标，需要适合分布式远程内存的基础设施。 正如 [19] 中所讨论的，RDMA 和更快的网络已经将远程内存中涉及的延迟降低了几个数量级，因此像 FaRM 和 RAMCloud [20, 21] 这样的系统可能非常有用。 处理系统范围状态的可变性、容错性和同步引入了许多在大数据领域已经考虑过的挑战。 一种方法的示例是 Spark 中的 RDD，它提供编程抽象和处理容错 



无服务器计算正在迅速发展，并迅速被接受为云计算的新前沿。 通过解决 我计划的无服务器运行时、调度和共享状态的问题 解决几个关键的开放性问题。 无疑多 未来几年将完成补充工作， 空间应该迅速演变成一个富有成果的研究领域 
